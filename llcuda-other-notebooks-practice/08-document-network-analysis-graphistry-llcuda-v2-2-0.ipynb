{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "header_cell",
      "cell_type": "markdown",
      "source": "# 08: Document Network Analysis with Graphistry\n\n**llcuda v2.2.0** | Kaggle 2\u00d7 Tesla T4 (30GB Total VRAM)\n\n---\n\n## \ud83c\udfaf Objective\n\nThis notebook demonstrates **document similarity networks** and **community detection** using llcuda v2.2.0 with graphistry[ai] visualization:\n\n### Architecture:\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GPU 0: llama-server (LLM)                             \u2502\n\u2502         Generate document summaries & extract topics   \u2502\n\u2502         tensor_split=\"1.0,0.0\"                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2193\n                  Document Similarity Graph\n                          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GPU 1: RAPIDS + Graphistry                            \u2502\n\u2502         Community detection + cluster visualization    \u2502\n\u2502         CUDA_VISIBLE_DEVICES=\"1\"                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### Workflow:\n1. Start llama-server on GPU 0\n2. Generate document summaries using LLM\n3. Build document similarity network on GPU 1\n4. Detect communities with Louvain algorithm (cuGraph)\n5. Visualize clusters with Graphistry\n6. LLM interprets community themes\n\n---\n\n**Previous:** [07-knowledge-graph-extraction](07-knowledge-graph-extraction-graphistry-llcuda-v2-2-0.ipynb)  \n**Next:** [09-large-models-kaggle](09-large-models-kaggle-llcuda-v2-2-0.ipynb)",
      "metadata": {}
    },
    {
      "id": "step0_header",
      "cell_type": "markdown",
      "source": "## Step 0: Add Graphistry Secrets in Kaggle\n\nGo to **Kaggle \u2192 Settings \u2192 Add-ons \u2192 Secrets** and add:\n- `Graphistry_Personal_Key_ID`\n- `Graphistry_Personal_Secret_Key`",
      "metadata": {}
    },
    {
      "id": "step1_header",
      "cell_type": "markdown",
      "source": "## Step 1: Verify Dual GPU Environment",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verifies dual T4 GPU setup for document network analysis combining LLM text processing with GPU-accelerated network analytics and visualization."
      ]
    },
    {
      "id": "step1_code",
      "cell_type": "code",
      "source": "import subprocess\nimport os\n\nprint(\"=\"*70)\nprint(\"\ud83d\udd0d SPLIT-GPU ENVIRONMENT CHECK\")\nprint(\"=\"*70)\n\nresult = subprocess.run(\n    [\"nvidia-smi\", \"--query-gpu=index,name,memory.total,memory.free\", \"--format=csv,noheader\"],\n    capture_output=True, text=True\n)\n\ngpus = result.stdout.strip().split('\\n')\nprint(f\"\\n\ud83d\udcca Detected {len(gpus)} GPU(s):\")\nfor gpu in gpus:\n    print(f\"   {gpu}\")\n\nif len(gpus) >= 2:\n    print(\"\\n\u2705 Dual T4 ready for split-GPU operation!\")\n    print(\"   GPU 0 \u2192 llama-server (LLM for summaries)\")\n    print(\"   GPU 1 \u2192 RAPIDS/Graphistry (community detection)\")\nelse:\n    print(\"\\n\u26a0\ufe0f Need 2 GPUs for split operation\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:23:30.405818Z",
          "iopub.execute_input": "2026-01-20T22:23:30.406107Z",
          "iopub.status.idle": "2026-01-20T22:23:30.444144Z",
          "shell.execute_reply.started": "2026-01-20T22:23:30.406079Z",
          "shell.execute_reply": "2026-01-20T22:23:30.443515Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udd0d SPLIT-GPU ENVIRONMENT CHECK\n======================================================================\n\n\ud83d\udcca Detected 2 GPU(s):\n   0, Tesla T4, 15360 MiB, 15096 MiB\n   1, Tesla T4, 15360 MiB, 15096 MiB\n\n\u2705 Dual T4 ready for split-GPU operation!\n   GPU 0 \u2192 llama-server (LLM for summaries)\n   GPU 1 \u2192 RAPIDS/Graphistry (community detection)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "step2_header",
      "cell_type": "markdown",
      "source": "## Step 2: Install Dependencies",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installs llcuda for LLM inference, RAPIDS for GPU graph analytics, and Graphistry for visualizing document similarity networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installs llcuda for LLM inference, RAPIDS cuGraph for GPU graph analytics, and Graphistry for visualizing document similarity networks."
      ]
    },
    {
      "id": "step2_code",
      "cell_type": "code",
      "source": "%%time\nprint(\"\ud83d\udce6 Installing dependencies...\")\n\n# Install llcuda v2.2.0\n!pip install -q --no-cache-dir git+https://github.com/llcuda/llcuda.git@v2.2.0\n\n# Install cuGraph (matching Kaggle RAPIDS 25.6.0)\n!pip install -q --extra-index-url=https://pypi.nvidia.com \"cugraph-cu12==25.6.*\"\n\n# Install Graphistry\n!pip install -q \"graphistry[ai]\"\n\n# Verify\nimport llcuda\nprint(f\"\\n\u2705 llcuda {llcuda.__version__} installed\")\n\ntry:\n    import cudf, cugraph\n    print(f\"\u2705 cuDF {cudf.__version__}\")\n    print(f\"\u2705 cuGraph {cugraph.__version__}\")\nexcept ImportError as e:\n    print(f\"\u26a0\ufe0f RAPIDS: {e}\")\n\ntry:\n    import graphistry\n    print(f\"\u2705 Graphistry {graphistry.__version__}\")\nexcept ImportError as e:\n    print(f\"\u26a0\ufe0f Graphistry: {e}\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:23:40.990326Z",
          "iopub.execute_input": "2026-01-20T22:23:40.990635Z",
          "iopub.status.idle": "2026-01-20T22:25:05.422772Z",
          "shell.execute_reply.started": "2026-01-20T22:23:40.990608Z",
          "shell.execute_reply": "2026-01-20T22:25:05.422026Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\ud83d\udce6 Installing dependencies...\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for llcuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.2 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m439.8/439.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING:root:llcuda: Library directory not found - shared libraries may not load correctly\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n======================================================================\n\ud83c\udfaf llcuda v2.2.0 First-Time Setup - Kaggle 2\u00d7 T4 Multi-GPU\n======================================================================\n\n\ud83c\udfae GPU Detected: Tesla T4 (Compute 7.5)\n  \u2705 Tesla T4 detected - Perfect for llcuda v2.1!\n\ud83c\udf10 Platform: Colab\n\n\ud83d\udce6 Downloading Kaggle 2\u00d7 T4 binaries (~961 MB)...\n    Features: FlashAttention + Tensor Cores + Multi-GPU tensor-split\n\n\u27a1\ufe0f  Attempt 1: HuggingFace (llcuda-v2.2.0-cuda12-kaggle-t4x2.tar.gz)\n\ud83d\udce5 Downloading v2.2.0 from HuggingFace Hub...\n   Repo: waqasm86/llcuda-binaries\n   File: v2.2.0/llcuda-v2.2.0-cuda12-kaggle-t4x2.tar.gz\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\nFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "v2.2.0/llcuda-v2.2.0-cuda12-kaggle-t4x2.(\u2026):   0%|          | 0.00/1.01G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc135bb488824c28b3db3b3bdf3ab51f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\ud83d\udd10 Verifying SHA256 checksum...\n   \u2705 Checksum verified\n\ud83d\udce6 Extracting llcuda-v2.2.0-cuda12-kaggle-t4x2.tar.gz...\nFound 21 files in archive\nExtracted 21 files to /root/.cache/llcuda/extract_2.2.0\n\u2705 Extraction complete!\n  Found bin/ and lib/ under /root/.cache/llcuda/extract_2.2.0/llcuda-v2.2.0-cuda12-kaggle-t4x2\n  Copied 13 binaries to /usr/local/lib/python3.12/dist-packages/llcuda/binaries/cuda12\n  Copied 0 libraries to /usr/local/lib/python3.12/dist-packages/llcuda/lib\n\u2705 Binaries installed successfully!\n\n\n\u2705 llcuda 2.2.0 installed\n\u2705 cuDF 25.06.00\n\u2705 cuGraph 25.06.00\n\u2705 Graphistry 0.50.4\nCPU times: user 46.1 s, sys: 10.5 s, total: 56.5 s\nWall time: 1min 24s\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configures Graphistry API authentication using Kaggle secrets for cloud-based document network visualization rendering."
      ]
    },
    {
      "id": "365e61a3-e832-4e9c-b5b8-55f842d2f4ac",
      "cell_type": "code",
      "source": "from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\ngraphistry.register(\n    api=3,\n    protocol=\"https\",\n    server=\"hub.graphistry.com\",\n    personal_key_id=user_secrets.get_secret(\"Graphistry_Personal_Key_ID\"),\n    personal_key_secret=user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:25:12.514497Z",
          "iopub.execute_input": "2026-01-20T22:25:12.515662Z",
          "iopub.status.idle": "2026-01-20T22:25:13.424498Z",
          "shell.execute_reply.started": "2026-01-20T22:25:12.515627Z",
          "shell.execute_reply": "2026-01-20T22:25:13.423916Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<graphistry.pygraphistry.GraphistryClient at 0x7aadb9c1b710>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "id": "step3_header",
      "cell_type": "markdown",
      "source": "## Step 3: Download GGUF Model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Downloads embedding or instruction-following model for document analysis, semantic similarity computation, and relationship extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Downloads language model for document embeddings, semantic analysis, and text similarity computation."
      ]
    },
    {
      "id": "step3_code",
      "cell_type": "code",
      "source": "%%time\nfrom huggingface_hub import hf_hub_download\nimport os\n\nMODEL_REPO = \"bartowski/Llama-3.2-3B-Instruct-GGUF\"\nMODEL_FILE = \"Llama-3.2-3B-Instruct-Q4_K_M.gguf\"\n\nprint(f\"\ud83d\udce5 Downloading {MODEL_FILE}...\")\n\nmodel_path = hf_hub_download(\n    repo_id=MODEL_REPO,\n    filename=MODEL_FILE,\n    local_dir=\"/kaggle/working/models\"\n)\n\nsize_gb = os.path.getsize(model_path) / (1024**3)\nprint(f\"\\n\u2705 Model downloaded: {model_path}\")\nprint(f\"   Size: {size_gb:.2f} GB\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:25:14.546156Z",
          "iopub.execute_input": "2026-01-20T22:25:14.546447Z",
          "iopub.status.idle": "2026-01-20T22:25:44.849071Z",
          "shell.execute_reply.started": "2026-01-20T22:25:14.546419Z",
          "shell.execute_reply": "2026-01-20T22:25:44.848415Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\ud83d\udce5 Downloading Llama-3.2-3B-Instruct-Q4_K_M.gguf...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Llama-3.2-3B-Instruct-Q4_K_M.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49b977d6f6534763a67df82b8cb157c2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n\u2705 Model downloaded: /kaggle/working/models/Llama-3.2-3B-Instruct-Q4_K_M.gguf\n   Size: 1.88 GB\nCPU times: user 5.7 s, sys: 8.99 s, total: 14.7 s\nWall time: 30.3 s\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "step4_header",
      "cell_type": "markdown",
      "source": "## Step 4: Start llama-server on GPU 0 Only",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deploys llama-server on GPU 0 using tensor-split configuration for document processing while keeping GPU 1 free for graph operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Starts llama-server on GPU 0 using single-GPU configuration (tensor-split 1.0,0.0) while reserving GPU 1 for graph operations."
      ]
    },
    {
      "id": "step4_code",
      "cell_type": "code",
      "source": "from llcuda.server import ServerManager\n\nprint(\"=\"*70)\nprint(\"\ud83d\ude80 STARTING LLAMA-SERVER ON GPU 0\")\nprint(\"=\"*70)\n\nprint(\"\\n\ud83d\udccb Configuration:\")\nprint(\"   GPU 0: 100% (llama-server for document summarization)\")\nprint(\"   GPU 1: 0% (reserved for RAPIDS/Graphistry)\")\n\nserver = ServerManager()\nserver.start_server(\n    model_path=model_path,\n    host=\"127.0.0.1\",\n    port=8090,\n    gpu_layers=99,\n    tensor_split=\"1.0,0.0\",\n    ctx_size=4096,\n)\n\nif server.check_server_health():\n    print(\"\\n\u2705 llama-server running on GPU 0!\")\nelse:\n    print(\"\\n\u274c Server failed to start\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:25:46.593966Z",
          "iopub.execute_input": "2026-01-20T22:25:46.594697Z",
          "iopub.status.idle": "2026-01-20T22:25:50.697003Z",
          "shell.execute_reply.started": "2026-01-20T22:25:46.594667Z",
          "shell.execute_reply": "2026-01-20T22:25:50.696245Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\ude80 STARTING LLAMA-SERVER ON GPU 0\n======================================================================\n\n\ud83d\udccb Configuration:\n   GPU 0: 100% (llama-server for document summarization)\n   GPU 1: 0% (reserved for RAPIDS/Graphistry)\nGPU Check:\n  Platform: kaggle\n  GPU: Tesla T4\n  Compute Capability: 7.5\n  Status: \u2713 Compatible\nStarting llama-server...\n  Executable: /usr/local/lib/python3.12/dist-packages/llcuda/binaries/cuda12/llama-server\n  Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf\n  GPU Layers: 99\n  Context Size: 4096\n  Server URL: http://127.0.0.1:8090\nWaiting for server to be ready....... \u2713 Ready in 4.0s\n\n\u2705 llama-server running on GPU 0!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "step5_header",
      "cell_type": "markdown",
      "source": "## Step 5: Generate Document Summaries and Topics",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verifies GPU memory allocation showing LLM loaded on GPU 0 with GPU 1 free for document network processing."
      ]
    },
    {
      "id": "step5_code",
      "cell_type": "code",
      "source": "from llcuda.api.client import LlamaCppClient\n\nprint(\"=\"*70)\nprint(\"\ud83d\udcc4 LLM-POWERED DOCUMENT ANALYSIS\")\nprint(\"=\"*70)\n\nclient = LlamaCppClient(base_url=\"http://127.0.0.1:8090\")\n\n# Sample documents about various GPU computing topics\ndocuments = [\n    # Deep Learning cluster\n    {\"id\": \"doc1\", \"text\": \"PyTorch provides dynamic computation graphs for deep learning. It integrates seamlessly with CUDA for GPU acceleration. Training neural networks on GPUs is significantly faster than CPUs.\"},\n    {\"id\": \"doc2\", \"text\": \"TensorFlow is Google's deep learning framework. It offers distributed training across multiple GPUs. TensorBoard provides visualization for training metrics.\"},\n    {\"id\": \"doc3\", \"text\": \"NVIDIA cuDNN accelerates deep neural network training. It provides highly optimized primitives for convolution and pooling operations on GPUs.\"},\n    \n    # Data Science cluster\n    {\"id\": \"doc4\", \"text\": \"RAPIDS cuDF provides a GPU DataFrame library. It accelerates pandas operations by 50-100\u00d7 using CUDA. Data scientists can process large datasets efficiently.\"},\n    {\"id\": \"doc5\", \"text\": \"cuML implements machine learning algorithms on GPUs. It supports classification, regression, and clustering with scikit-learn API compatibility.\"},\n    {\"id\": \"doc6\", \"text\": \"Apache Spark can leverage GPUs for distributed computing. RAPIDS Accelerator speeds up Spark SQL and DataFrame operations on GPU clusters.\"},\n    \n    # Inference cluster\n    {\"id\": \"doc7\", \"text\": \"llama.cpp enables efficient LLM inference on GPUs. GGUF quantization reduces model size while maintaining quality. It supports multi-GPU tensor parallelism.\"},\n    {\"id\": \"doc8\", \"text\": \"TensorRT optimizes neural network inference. It provides INT8 and FP16 precision for faster inference. Deployed models achieve low latency on NVIDIA GPUs.\"},\n    {\"id\": \"doc9\", \"text\": \"ONNX Runtime accelerates machine learning inference. It supports multiple hardware backends including CUDA. Models can be optimized for production deployment.\"},\n    \n    # Visualization cluster\n    {\"id\": \"doc10\", \"text\": \"Graphistry provides GPU-accelerated graph visualization. It handles millions of nodes and edges interactively. RAPIDS integration enables visual analytics at scale.\"},\n    {\"id\": \"doc11\", \"text\": \"cuGraph implements graph algorithms on GPUs. PageRank and community detection run 100\u00d7 faster than NetworkX. It integrates with Graphistry for visualization.\"},\n]\n\n# Extract topics from each document\ndoc_topics = []\n\nfor doc in documents:\n    prompt = f\"\"\"Summarize this document in 5 words maximum, focusing on the main topic:\n\n{doc['text']}\n\n5-word summary:\"\"\"\n    \n    response = client.chat.create(\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        max_tokens=20,\n        temperature=0.3,\n    )\n    \n    summary = response.choices[0].message.content.strip()\n    doc_topics.append({\"id\": doc[\"id\"], \"summary\": summary, \"text\": doc[\"text\"]})\n    print(f\"{doc['id']}: {summary}\")\n\nprint(f\"\\n\u2705 Generated {len(doc_topics)} document summaries\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:25:52.365840Z",
          "iopub.execute_input": "2026-01-20T22:25:52.366181Z",
          "iopub.status.idle": "2026-01-20T22:25:55.539221Z",
          "shell.execute_reply.started": "2026-01-20T22:25:52.366154Z",
          "shell.execute_reply": "2026-01-20T22:25:55.538642Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udcc4 LLM-POWERED DOCUMENT ANALYSIS\n======================================================================\ndoc1: {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}}\ndoc2: {\"name\": \"TensorFlow Deep Learning Framework\", \"parameters\": {\"\": \"summary\"}}\ndoc3: {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}}\ndoc4: {\"name\": \"cuDF\", \"parameters\": {\"key\": \"GPU DataFrame library\"}}\ndoc5: {\"name\": \"Summary\", \"parameters\": {\"summary\": \"Machine Learning on GPUs\"}}\ndoc6: {\"name\": \"Spark uses GPUs efficiently\", \"parameters\": {\"\"}}\ndoc7: {\"name\": \"LLM inference on GPUs\", \"parameters\": {\"\": \"summary\"}}\ndoc8: {\"name\": \"summarize\", \"parameters\": {\"s\": \"TensorRT optimization for neural\ndoc9: {\"name\": \"ONNX Runtime Acceleration\", \"parameters\": {\"\": \"machine learning\"}}\ndoc10: {\"name\": \"graph visualization software\", \"parameters\": {\"scale\": \"at\"}}\ndoc11: {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}}\n\n\u2705 Generated 11 document summaries\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "step6_header",
      "cell_type": "markdown",
      "source": "## Step 6: Initialize RAPIDS on GPU 1",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initializes RAPIDS on GPU 1 via CUDA_VISIBLE_DEVICES environment variable for GPU-accelerated document graph operations."
      ]
    },
    {
      "id": "step6_code",
      "cell_type": "code",
      "source": "import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\nprint(\"=\"*70)\nprint(\"\ud83d\udd25 INITIALIZING RAPIDS ON GPU 1\")\nprint(\"=\"*70)\n\nimport cudf\nimport cupy as cp\n\nprint(f\"\\n\ud83d\udcca RAPIDS GPU Info:\")\ndevice = cp.cuda.Device(0)  # Device 0 in filtered view = actual GPU 1\nprint(f\"   Device: {device.id} (filtered view)\")\nprint(f\"   Actual GPU: 1 (Tesla T4)\")\n\nprint(f\"\\n\u2705 RAPIDS initialized on GPU 1\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:00.938288Z",
          "iopub.execute_input": "2026-01-20T22:26:00.938586Z",
          "iopub.status.idle": "2026-01-20T22:26:00.944329Z",
          "shell.execute_reply.started": "2026-01-20T22:26:00.938560Z",
          "shell.execute_reply": "2026-01-20T22:26:00.943449Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udd25 INITIALIZING RAPIDS ON GPU 1\n======================================================================\n\n\ud83d\udcca RAPIDS GPU Info:\n   Device: 0 (filtered view)\n   Actual GPU: 1 (Tesla T4)\n\n\u2705 RAPIDS initialized on GPU 1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "step7_header",
      "cell_type": "markdown",
      "source": "## Step 7: Build Document Similarity Network",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loads sample document corpus and preprocesses text for similarity analysis and network construction."
      ]
    },
    {
      "id": "step7_code",
      "cell_type": "code",
      "source": "import cugraph\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nprint(\"=\"*70)\nprint(\"\ud83d\udcca BUILDING DOCUMENT SIMILARITY NETWORK\")\nprint(\"=\"*70)\n\n# Calculate TF-IDF similarity between documents\ntexts = [doc['text'] for doc in doc_topics]\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(texts)\nsimilarity_matrix = cosine_similarity(tfidf_matrix)\n\n# Create edges for documents with similarity > threshold\nthreshold = 0.15  # Lower threshold to create more connections\nedges_list = []\n\nfor i in range(len(documents)):\n    for j in range(i + 1, len(documents)):\n        similarity = similarity_matrix[i, j]\n        if similarity > threshold:\n            edges_list.append({\n                'source': i,\n                'target': j,\n                'weight': float(similarity)\n            })\n\n# Create cuDF edge list\nedges_cudf = cudf.DataFrame(edges_list)\n\nprint(f\"\\n\ud83d\udcca Document Similarity Network:\")\nprint(f\"   Nodes (documents): {len(documents)}\")\nprint(f\"   Edges (similarities > {threshold}): {len(edges_cudf)}\")\nprint(f\"   Average similarity: {edges_cudf['weight'].mean():.3f}\")\n\n# Create cuGraph\nG = cugraph.Graph()\nG.from_cudf_edgelist(edges_cudf, source='source', destination='target', edge_attr='weight')\n\nprint(f\"\\n\u2705 Document network created on GPU 1\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:03.026529Z",
          "iopub.execute_input": "2026-01-20T22:26:03.026850Z",
          "iopub.status.idle": "2026-01-20T22:26:04.069520Z",
          "shell.execute_reply.started": "2026-01-20T22:26:03.026822Z",
          "shell.execute_reply": "2026-01-20T22:26:04.068902Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udcca BUILDING DOCUMENT SIMILARITY NETWORK\n======================================================================\n\n\ud83d\udcca Document Similarity Network:\n   Nodes (documents): 11\n   Edges (similarities > 0.15): 9\n   Average similarity: 0.210\n\n\u2705 Document network created on GPU 1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "step8_header",
      "cell_type": "markdown",
      "source": "## Step 8: Community Detection with Louvain Algorithm",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generates document embeddings using LLM on GPU 0, creating vector representations for semantic similarity computation."
      ]
    },
    {
      "id": "step8_code",
      "cell_type": "code",
      "source": "print(\"=\"*70)\nprint(\"\ud83d\udd2c COMMUNITY DETECTION (GPU-ACCELERATED)\")\nprint(\"=\"*70)\n\n# Run Louvain community detection\npartition_df, modularity_score = cugraph.louvain(G)\n\n# Map communities back to documents\ncommunities_pd = partition_df.to_pandas()\ndoc_communities = {}\nfor _, row in communities_pd.iterrows():\n    doc_id = int(row['vertex'])\n    community_id = int(row['partition'])\n    doc_communities[doc_id] = community_id\n\n# Group documents by community\ncommunity_groups = {}\nfor doc_id, community_id in doc_communities.items():\n    if community_id not in community_groups:\n        community_groups[community_id] = []\n    community_groups[community_id].append(doc_id)\n\nprint(f\"\\n\ud83d\udcca Detected {len(community_groups)} communities:\")\nfor community_id, doc_ids in sorted(community_groups.items()):\n    doc_names = [doc_topics[i]['id'] for i in doc_ids]\n    print(f\"   Community {community_id}: {', '.join(doc_names)}\")\n\nprint(\"\\n\u2705 Community detection complete on GPU 1\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:13.581220Z",
          "iopub.execute_input": "2026-01-20T22:26:13.581734Z",
          "iopub.status.idle": "2026-01-20T22:26:13.599583Z",
          "shell.execute_reply.started": "2026-01-20T22:26:13.581704Z",
          "shell.execute_reply": "2026-01-20T22:26:13.598894Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udd2c COMMUNITY DETECTION (GPU-ACCELERATED)\n======================================================================\n\n\ud83d\udcca Detected 3 communities:\n   Community 0: doc1, doc3, doc2, doc8\n   Community 1: doc11, doc5, doc10\n   Community 2: doc4, doc6\n\n\u2705 Community detection complete on GPU 1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 10
    },
    {
      "id": "step9_header",
      "cell_type": "markdown",
      "source": "## Step 9: Graph Analytics on Communities",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computes network metrics (centrality, clustering coefficient) to identify influential documents and network structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computes pairwise document similarity matrix using cosine similarity on embeddings, identifying related documents."
      ]
    },
    {
      "id": "step9_code",
      "cell_type": "code",
      "source": "print(\"=\"*70)\nprint(\"\ud83d\udcca DOCUMENT NETWORK ANALYTICS\")\nprint(\"=\"*70)\n\n# PageRank - identify important documents\nprint(\"\\n\ud83d\udcca PageRank Analysis (Document Importance):\")\npagerank = cugraph.pagerank(G)\npagerank = pagerank.sort_values('pagerank', ascending=False)\n\nfor _, row in pagerank.to_pandas().head(5).iterrows():\n    doc_id = int(row['vertex'])\n    score = row['pagerank']\n    doc_name = doc_topics[doc_id]['id']\n    summary = doc_topics[doc_id]['summary']\n    print(f\"   {doc_name}: {score:.4f} - {summary}\")\n\n# Betweenness Centrality - bridge documents between communities\nprint(\"\\n\ud83d\udcca Betweenness Centrality (Bridge Documents):\")\nbc = cugraph.betweenness_centrality(G)\nbc = bc.sort_values('betweenness_centrality', ascending=False)\n\nfor _, row in bc.to_pandas().head(5).iterrows():\n    doc_id = int(row['vertex'])\n    score = row['betweenness_centrality']\n    doc_name = doc_topics[doc_id]['id']\n    summary = doc_topics[doc_id]['summary']\n    print(f\"   {doc_name}: {score:.4f} - {summary}\")\n\nprint(\"\\n\u2705 Graph analytics computed on GPU 1\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:17.085119Z",
          "iopub.execute_input": "2026-01-20T22:26:17.085739Z",
          "iopub.status.idle": "2026-01-20T22:26:17.438243Z",
          "shell.execute_reply.started": "2026-01-20T22:26:17.085709Z",
          "shell.execute_reply": "2026-01-20T22:26:17.437636Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udcca DOCUMENT NETWORK ANALYTICS\n======================================================================\n\n\ud83d\udcca PageRank Analysis (Document Importance):\n   doc1: 0.1802 - {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}}\n   doc11: 0.1567 - {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}}\n   doc3: 0.1392 - {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}}\n   doc4: 0.1111 - {\"name\": \"cuDF\", \"parameters\": {\"key\": \"GPU DataFrame library\"}}\n   doc6: 0.1111 - {\"name\": \"Spark uses GPUs efficiently\", \"parameters\": {\"\"}}\n\n\ud83d\udcca Betweenness Centrality (Bridge Documents):\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/cugraph/link_analysis/pagerank.py:232: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n  warnings.warn(warning_msg, UserWarning)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   doc1: 0.3393 - {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}}\n   doc11: 0.3214 - {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}}\n   doc3: 0.0179 - {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}}\n   doc2: 0.0000 - {\"name\": \"TensorFlow Deep Learning Framework\", \"parameters\": {\"\": \"summary\"}}\n   doc8: 0.0000 - {\"name\": \"summarize\", \"parameters\": {\"s\": \"TensorRT optimization for neural\n\n\u2705 Graph analytics computed on GPU 1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "id": "step10_header",
      "cell_type": "markdown",
      "source": "## Step 10: LLM Analysis of Community Themes",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computes network metrics (centrality, clustering coefficient) to identify influential documents and network structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Constructs document network graph on GPU 1 where nodes are documents and edges represent similarity above threshold."
      ]
    },
    {
      "id": "step10_code",
      "cell_type": "code",
      "source": "print(\"=\"*70)\nprint(\"\ud83e\udd14 LLM ANALYSIS OF COMMUNITY THEMES\")\nprint(\"=\"*70)\n\nfor community_id, doc_ids in sorted(community_groups.items()):\n    # Get summaries for this community\n    summaries = [doc_topics[i]['summary'] for i in doc_ids]\n    doc_names = [doc_topics[i]['id'] for i in doc_ids]\n    \n    prompt = f\"\"\"These documents form a cluster based on similarity:\n{', '.join([f\"{name}: {summary}\" for name, summary in zip(doc_names, summaries)])}\n\nWhat is the common theme? Answer in one phrase (3-5 words):\"\"\"\n    \n    response = client.chat.create(\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        max_tokens=20,\n        temperature=0.5\n    )\n    \n    theme = response.choices[0].message.content.strip()\n    print(f\"\\n\ud83d\udccc Community {community_id}: {theme}\")\n    print(f\"   Documents: {', '.join(doc_names)}\")\n\nprint(\"\\n\u2705 Simultaneous GPU operation:\")\nprint(\"   GPU 0: LLM inference (theme analysis)\")\nprint(\"   GPU 1: Graph analytics (previously computed)\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:20.758982Z",
          "iopub.execute_input": "2026-01-20T22:26:20.759697Z",
          "iopub.status.idle": "2026-01-20T22:26:21.579497Z",
          "shell.execute_reply.started": "2026-01-20T22:26:20.759670Z",
          "shell.execute_reply": "2026-01-20T22:26:21.578903Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83e\udd14 LLM ANALYSIS OF COMMUNITY THEMES\n======================================================================\n\n\ud83d\udccc Community 0: {\"name\": \"Deep Learning Frameworks\", \"parameters\": {}}\n   Documents: doc1, doc3, doc2, doc8\n\n\ud83d\udccc Community 1: {\"name\": \"Graph Algorithms\", \"parameters\": {}}\n   Documents: doc11, doc5, doc10\n\n\ud83d\udccc Community 2: {\"name\": \"GPU usage\", \"parameters\": {}}\n   Documents: doc4, doc6\n\n\u2705 Simultaneous GPU operation:\n   GPU 0: LLM inference (theme analysis)\n   GPU 1: Graph analytics (previously computed)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "id": "step11_header",
      "cell_type": "markdown",
      "source": "## Step 11: Graphistry Visualization",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runs GPU-accelerated community detection on document network to discover thematic clusters and topic groups."
      ]
    },
    {
      "id": "step11_code",
      "cell_type": "code",
      "source": "print(\"=\"*70)\nprint(\"\ud83c\udfa8 GRAPHISTRY DOCUMENT NETWORK VISUALIZATION\")\nprint(\"=\"*70)\n\nimport graphistry\nfrom kaggle_secrets import UserSecretsClient\nimport pandas as pd\nimport numpy as np\n\n# --- 1. Register Graphistry ---\nprint(\"\\n\ud83d\udd10 Registering with Graphistry...\")\ntry:\n    user_secrets = UserSecretsClient()\n    graphistry_key_id = user_secrets.get_secret(\"Graphistry_Personal_Key_ID\")\n    graphistry_secret = user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n\n    graphistry.register(\n        api=3,\n        protocol=\"https\",\n        server=\"hub.graphistry.com\",\n        personal_key_id=graphistry_key_id,\n        personal_key_secret=graphistry_secret\n    )\n    print(\"\u2705 Graphistry registered successfully\")\nexcept Exception as e:\n    print(f\"\u26a0\ufe0f Graphistry registration failed: {e}\")\n    print(\"   Add secrets: Graphistry_Personal_Key_ID, Graphistry_Personal_Secret_Key\")\n\n# --- 2. Prepare visualization data ---\nprint(\"\\n\ud83d\udcca Preparing document network data...\")\n\n# Ensure edges_pd exists\nif 'edges_pd' not in locals() and 'edges_pd' not in globals():\n    if 'edges_cudf' in locals() or 'edges_cudf' in globals():\n        edges_pd = edges_cudf.to_pandas()\n    else:\n        raise ValueError(\"No edges data found\")\n\nprint(f\"   Edge data shape: {edges_pd.shape}\")\n\n# Ensure nodes data with all metrics\nif 'pagerank_pd' not in locals():\n    pagerank_pd = pagerank.to_pandas()\nif 'bc_pd' not in locals():\n    bc_pd = bc.to_pandas()\nif 'communities_pd' not in locals():\n    communities_pd = communities.to_pandas()\n\n# Build comprehensive nodes DataFrame\nnodes_pd = pd.DataFrame({\n    'node_id': list(range(len(doc_topics))),\n    'doc_id': [doc['id'] for doc in doc_topics],\n    'summary': [doc['summary'] for doc in doc_topics],\n    'text_preview': [doc['text'][:100] + '...' if len(doc['text']) > 100 else doc['text'] for doc in doc_topics]\n})\n\n# Merge PageRank\nnodes_pd = nodes_pd.merge(\n    pagerank_pd.rename(columns={'vertex': 'node_id'}),\n    on='node_id',\n    how='left'\n)\n\n# Merge Betweenness Centrality\nnodes_pd = nodes_pd.merge(\n    bc_pd.rename(columns={'vertex': 'node_id'}),\n    on='node_id',\n    how='left'\n)\n\n# Merge Communities\nnodes_pd = nodes_pd.merge(\n    communities_pd.rename(columns={'vertex': 'node_id', 'partition': 'community'}),\n    on='node_id',\n    how='left'\n)\nnodes_pd['community'] = nodes_pd['community'].fillna(0).astype(int)\n\n# --- 3. Compute degree centrality ---\nprint(\"   Computing degree centrality...\")\ndegree_in = edges_pd.groupby('target').size().reset_index(name='degree_in').rename(columns={'target': 'node_id'})\ndegree_out = edges_pd.groupby('source').size().reset_index(name='degree_out').rename(columns={'source': 'node_id'})\n\nnodes_pd = nodes_pd.merge(degree_in, on='node_id', how='left')\nnodes_pd = nodes_pd.merge(degree_out, on='node_id', how='left')\nnodes_pd['degree_in'] = nodes_pd['degree_in'].fillna(0).astype(int)\nnodes_pd['degree_out'] = nodes_pd['degree_out'].fillna(0).astype(int)\nnodes_pd['total_degree'] = nodes_pd['degree_in'] + nodes_pd['degree_out']\n\n# --- 4. Role classification ---\nprint(\"   Classifying document roles...\")\n\ndef classify_doc_role(row):\n    \"\"\"Classify documents: Hub (high centrality), Bridge (high betweenness), Peripheral.\"\"\"\n    pr = row['pagerank']\n    bc = row['betweenness_centrality']\n    pr_threshold = nodes_pd['pagerank'].median()\n    bc_threshold = nodes_pd['betweenness_centrality'].median()\n\n    if pr > pr_threshold and bc > bc_threshold:\n        return 'Hub'\n    elif bc > bc_threshold:\n        return 'Bridge'\n    else:\n        return 'Peripheral'\n\nnodes_pd['role'] = nodes_pd.apply(classify_doc_role, axis=1)\n\n# --- 5. Size encoding (normalized PageRank) ---\npr_min = nodes_pd['pagerank'].min()\npr_max = nodes_pd['pagerank'].max()\nif pr_max > pr_min:\n    nodes_pd['node_size'] = 25 + (nodes_pd['pagerank'] - pr_min) / (pr_max - pr_min) * 75\nelse:\n    nodes_pd['node_size'] = 50\n\n# --- 6. Rich tooltips ---\nnodes_pd['point_title'] = nodes_pd.apply(\n    lambda row: f\"{row['doc_id']}: {row['summary']}\\n\" +\n                f\"Community: {row['community']}\\n\" +\n                f\"Role: {row['role']}\\n\" +\n                f\"PageRank: {row['pagerank']:.4f}\\n\" +\n                f\"Betweenness: {row['betweenness_centrality']:.4f}\\n\" +\n                f\"Degree: {int(row['total_degree'])}\",\n    axis=1\n)\n\nedges_pd['edge_title'] = edges_pd.apply(\n    lambda row: f\"Similarity: {row['weight']:.3f}\",\n    axis=1\n)\n\nprint(f\"\\n\ud83d\udcca Document Network Summary:\")\nprint(f\"   Documents: {len(nodes_pd)}\")\nprint(f\"   Similarity Edges: {len(edges_pd)}\")\nprint(f\"   Communities: {nodes_pd['community'].nunique()}\")\nprint(f\"   Avg similarity: {edges_pd['weight'].mean():.3f}\")\n\n# --- 7. Create Graphistry visualization ---\nprint(\"\\n\ud83c\udfa8 Creating Graphistry visualization...\")\n\n# Color palettes\ncommunity_colors = {\n    0: '#FF6B6B',  # Red - Deep Learning\n    1: '#4ECDC4',  # Teal - Data Science\n    2: '#45B7D1',  # Blue - Inference\n    3: '#FFA07A',  # Orange - Visualization\n    4: '#98D8C8',  # Mint\n}\n\nrole_icons = {\n    'Hub': 'star',\n    'Bridge': 'exchange-alt',\n    'Peripheral': 'circle'\n}\n\n# Bind and create visualization\ng = graphistry.bind(\n    source='source',\n    destination='target',\n    node='node_id',\n    point_title='point_title',\n    edge_title='edge_title'\n)\n\nplotter = (\n    g.edges(edges_pd)\n    .nodes(nodes_pd)\n    .encode_point_color('community', categorical_mapping=community_colors, default_mapping='#CCCCCC')\n    .encode_point_size('node_size')\n    .encode_point_icon('role', categorical_mapping=role_icons, default_mapping='circle')\n    .encode_edge_color('weight', ['#E8E8E8', '#6C7A89', '#2C3E50'], as_continuous=True)\n    .settings(url_params={\n        'play': 0,\n        'pointSize': 2.5,\n        'edgeOpacity': 0.4,\n        'bg': '%23FFFFFF',\n        'showArrows': 'false',\n        'showLabels': 'true'\n    })\n)\n\n# --- 8. Launch visualization ---\ntry:\n    url = plotter.plot(\n        render=False,\n        name=\"Document Similarity Network - llcuda v2.2.0\",\n        description=f\"{len(nodes_pd)} documents clustered into {nodes_pd['community'].nunique()} communities\"\n    )\n\n    print(f\"\\n\ud83d\ude80 Visualization Created Successfully!\")\n    print(f\"\\n\ud83d\udd17 Graphistry URL:\")\n    print(f\"   {url}\")\n    print(f\"\\n\ud83d\udccc Features:\")\n    print(f\"   \u2713 Color-coded by community (document clusters)\")\n    print(f\"   \u2713 Size scaled by PageRank (document importance)\")\n    print(f\"   \u2713 Icons show role (Hub \u2b50, Bridge \u2194\ufe0f, Peripheral \u25cb)\")\n    print(f\"   \u2713 Edge color intensity = similarity strength\")\n    print(f\"   \u2713 Interactive tooltips with doc summaries\")\n\n    from IPython.display import display, HTML\n    display(HTML(\n        f'<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); '\n        f'border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\">'\n        f'<h3 style=\"margin:0 0 10px 0;\">\ud83d\udcc4 Document Network Dashboard</h3>'\n        f'<p style=\"margin:5px 0;\">GPU computing topics clustered by similarity</p>'\n        f'<a href=\"{url}\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; '\n        f'background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; '\n        f'box-shadow:0 2px 4px rgba(0,0,0,0.1);\">\ud83d\ude80 Open Interactive Visualization</a>'\n        f'</div>'\n    ))\n\nexcept Exception as e:\n    print(f\"\\n\u274c Visualization error: {e}\")\n    print(f\"   Data prepared successfully - {len(nodes_pd)} nodes, {len(edges_pd)} edges\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"\u2705 Document network visualization complete\")\nprint(\"=\"*70)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:28.129884Z",
          "iopub.execute_input": "2026-01-20T22:26:28.130187Z",
          "iopub.status.idle": "2026-01-20T22:26:30.352534Z",
          "shell.execute_reply.started": "2026-01-20T22:26:28.130161Z",
          "shell.execute_reply": "2026-01-20T22:26:30.351971Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83c\udfa8 GRAPHISTRY DOCUMENT NETWORK VISUALIZATION\n======================================================================\n\n\ud83d\udd10 Registering with Graphistry...\n\u2705 Graphistry registered successfully\n\n\ud83d\udcca Preparing document network data...\n   Edge data shape: (9, 3)\n   Computing degree centrality...\n   Classifying document roles...\n\n\ud83d\udcca Document Network Summary:\n   Documents: 11\n   Similarity Edges: 9\n   Communities: 3\n   Avg similarity: 0.210\n\n\ud83c\udfa8 Creating Graphistry visualization...\n\n\ud83d\ude80 Visualization Created Successfully!\n\n\ud83d\udd17 Graphistry URL:\n   https://hub.graphistry.com/graph/graph.html?dataset=c4dd79ee95ae4a5488d8d0d280704c57&type=arrow&viztoken=d2f845dc-723f-4482-aa1b-f6d4f8c2676b&usertag=03c49df5-pygraphistry-0.50.4&splashAfter=1768948005&info=true&play=0&pointSize=2.5&edgeOpacity=0.4&bg=%23FFFFFF&showArrows=false&showLabels=true\n\n\ud83d\udccc Features:\n   \u2713 Color-coded by community (document clusters)\n   \u2713 Size scaled by PageRank (document importance)\n   \u2713 Icons show role (Hub \u2b50, Bridge \u2194\ufe0f, Peripheral \u25cb)\n   \u2713 Edge color intensity = similarity strength\n   \u2713 Interactive tooltips with doc summaries\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\"><h3 style=\"margin:0 0 10px 0;\">\ud83d\udcc4 Document Network Dashboard</h3><p style=\"margin:5px 0;\">GPU computing topics clustered by similarity</p><a href=\"https://hub.graphistry.com/graph/graph.html?dataset=c4dd79ee95ae4a5488d8d0d280704c57&type=arrow&viztoken=d2f845dc-723f-4482-aa1b-f6d4f8c2676b&usertag=03c49df5-pygraphistry-0.50.4&splashAfter=1768948005&info=true&play=0&pointSize=2.5&edgeOpacity=0.4&bg=%23FFFFFF&showArrows=false&showLabels=true\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.1);\">\ud83d\ude80 Open Interactive Visualization</a></div>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n======================================================================\n\u2705 Document network visualization complete\n======================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "id": "step12_header",
      "cell_type": "markdown",
      "source": "## Step 12: Detailed Community Report",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computes network metrics (degree centrality, PageRank) on GPU 1 to identify most influential and central documents."
      ]
    },
    {
      "id": "step12_code",
      "cell_type": "code",
      "source": "print(\"=\"*70)\nprint(\"\ud83d\udccb DETAILED COMMUNITY REPORT\")\nprint(\"=\"*70)\n\nfor community_id, doc_ids in sorted(community_groups.items()):\n    print(f\"\\n\ud83d\udccc Community {community_id}:\")\n    print(f\"   Size: {len(doc_ids)} documents\")\n    \n    print(f\"\\n   Documents:\")\n    for doc_id in doc_ids:\n        doc = doc_topics[doc_id]\n        pr_score = pagerank_pd[pagerank_pd['vertex'] == doc_id]['pagerank'].values\n        pr_score = pr_score[0] if len(pr_score) > 0 else 0\n        print(f\"      \u2022 {doc['id']}: {doc['summary']} (PageRank: {pr_score:.4f})\")\n    \n    # Avg similarity within community\n    intra_edges = edges_cudf[\n        (edges_cudf['source'].isin(doc_ids)) & \n        (edges_cudf['target'].isin(doc_ids))\n    ]\n    if len(intra_edges) > 0:\n        avg_sim = intra_edges['weight'].mean()\n        print(f\"\\n   Avg intra-community similarity: {avg_sim:.3f}\")\n\nprint(\"\\n\u2705 Community analysis complete\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:41.481894Z",
          "iopub.execute_input": "2026-01-20T22:26:41.482199Z",
          "iopub.status.idle": "2026-01-20T22:26:41.547757Z",
          "shell.execute_reply.started": "2026-01-20T22:26:41.482172Z",
          "shell.execute_reply": "2026-01-20T22:26:41.547179Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udccb DETAILED COMMUNITY REPORT\n======================================================================\n\n\ud83d\udccc Community 0:\n   Size: 4 documents\n\n   Documents:\n      \u2022 doc1: {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}} (PageRank: 0.1802)\n      \u2022 doc3: {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}} (PageRank: 0.1392)\n      \u2022 doc2: {\"name\": \"TensorFlow Deep Learning Framework\", \"parameters\": {\"\": \"summary\"}} (PageRank: 0.0980)\n      \u2022 doc8: {\"name\": \"summarize\", \"parameters\": {\"s\": \"TensorRT optimization for neural (PageRank: 0.0881)\n\n   Avg intra-community similarity: 0.220\n\n\ud83d\udccc Community 1:\n   Size: 3 documents\n\n   Documents:\n      \u2022 doc11: {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}} (PageRank: 0.1567)\n      \u2022 doc5: {\"name\": \"Summary\", \"parameters\": {\"summary\": \"Machine Learning on GPUs\"}} (PageRank: 0.0639)\n      \u2022 doc10: {\"name\": \"graph visualization software\", \"parameters\": {\"scale\": \"at\"}} (PageRank: 0.0516)\n\n   Avg intra-community similarity: 0.192\n\n\ud83d\udccc Community 2:\n   Size: 2 documents\n\n   Documents:\n      \u2022 doc4: {\"name\": \"cuDF\", \"parameters\": {\"key\": \"GPU DataFrame library\"}} (PageRank: 0.1111)\n      \u2022 doc6: {\"name\": \"Spark uses GPUs efficiently\", \"parameters\": {\"\"}} (PageRank: 0.1111)\n\n   Avg intra-community similarity: 0.166\n\n\u2705 Community analysis complete\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 14
    },
    {
      "id": "step13_header",
      "cell_type": "markdown",
      "source": "## Step 13: Monitor Both GPUs",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates Graphistry visualization of document network with community colors, node sizes by centrality, and interactive filtering."
      ]
    },
    {
      "id": "step13_code",
      "cell_type": "code",
      "source": "print(\"=\"*70)\nprint(\"\ud83d\udcca DUAL GPU MONITORING\")\nprint(\"=\"*70)\n\n!nvidia-smi\n\nprint(\"\\n\ud83d\udca1 Split-GPU Operation:\")\nprint(\"   GPU 0: llama-server (document summarization)\")\nprint(\"   GPU 1: RAPIDS (community detection, graph analytics)\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:26:44.898861Z",
          "iopub.execute_input": "2026-01-20T22:26:44.899645Z",
          "iopub.status.idle": "2026-01-20T22:26:45.155045Z",
          "shell.execute_reply.started": "2026-01-20T22:26:44.899574Z",
          "shell.execute_reply": "2026-01-20T22:26:45.154012Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\n\ud83d\udcca DUAL GPU MONITORING\n======================================================================\nTue Jan 20 22:26:44 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   55C    P0             28W /   70W |    2679MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   55C    P0             28W /   70W |     103MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n\ud83d\udca1 Split-GPU Operation:\n   GPU 0: llama-server (document summarization)\n   GPU 1: RAPIDS (community detection, graph analytics)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 15
    },
    {
      "id": "step14_header",
      "cell_type": "markdown",
      "source": "## Step 14: Cleanup",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verifies dual T4 GPU availability for document network analysis workflow combining LLM text processing with GPU-accelerated network analytics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uses LLM on GPU 0 to generate natural language summaries of detected document communities and key themes."
      ]
    },
    {
      "id": "step14_code",
      "cell_type": "code",
      "source": "print(\"\ud83d\uded1 Stopping llama-server...\")\nserver.stop_server()\n\n# Clear RAPIDS memory\nimport gc\ndel G, edges_cudf, pagerank, bc, communities\ngc.collect()\n\nprint(\"\\n\u2705 Resources cleaned up\")\nprint(\"\\n\ud83d\udcca Final GPU Status:\")\n!nvidia-smi --query-gpu=index,memory.used,memory.free --format=csv",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-20T22:27:13.981270Z",
          "iopub.execute_input": "2026-01-20T22:27:13.981614Z",
          "iopub.status.idle": "2026-01-20T22:27:14.777459Z",
          "shell.execute_reply.started": "2026-01-20T22:27:13.981562Z",
          "shell.execute_reply": "2026-01-20T22:27:14.776456Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\ud83d\uded1 Stopping llama-server...\n\n\u2705 Resources cleaned up\n\n\ud83d\udcca Final GPU Status:\nindex, memory.used [MiB], memory.free [MiB]\n0, 109 MiB, 14987 MiB\n1, 3 MiB, 15093 MiB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 16
    },
    {
      "id": "summary",
      "cell_type": "markdown",
      "source": "## \ud83d\udcda Summary\n\n### Document Network Analysis Workflow:\n1. **GPU 0**: LLM generates document summaries\n2. **CPU**: TF-IDF calculates document similarity\n3. **GPU 1**: cuGraph builds similarity network\n4. **GPU 1**: Louvain algorithm detects communities\n5. **GPU 0**: LLM interprets community themes\n6. **Graphistry**: Interactive visualization with communities\n\n### Key Integration Points:\n- \u2705 LLM for document summarization and theme extraction\n- \u2705 cuGraph for GPU-accelerated community detection (Louvain)\n- \u2705 Graphistry for community-colored network visualization\n- \u2705 PageRank & Betweenness for document importance ranking\n\n### Algorithms Used:\n- **Louvain**: Community detection (finds document clusters)\n- **PageRank**: Document importance (citation-like ranking)\n- **Betweenness Centrality**: Bridge documents (connect communities)\n- **TF-IDF + Cosine Similarity**: Document similarity metric\n\n### Split-GPU Architecture:\n```python\n# GPU 0: llama-server\ntensor_split=\"1.0,0.0\"  # 100% on GPU 0\n\n# GPU 1: RAPIDS\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nimport cudf, cugraph  # Uses GPU 1\n```\n\n---\n\n**Next:** [09-large-models-kaggle](09-large-models-kaggle-llcuda-v2-2-0.ipynb)",
      "metadata": {}
    }
  ]
}