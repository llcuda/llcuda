CUDA-accelerated LLM inference for Python, Version 1.1.5 - PyTorch-style, zero-configuration, works on Colab/Kaggle/local GPUs.
