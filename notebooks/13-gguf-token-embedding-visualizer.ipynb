{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® GGUF Token Embedding Visualizer\n",
    "\n",
    "**Complementary to [Transformers-Explainer](https://poloclub.github.io/transformer-explainer/)** - Embedding Layer Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook visualizes **how GGUF models represent tokens as high-dimensional vectors** and explores the **semantic structure** of the embedding space using GPU-accelerated dimensionality reduction.\n",
    "\n",
    "### What Transformers-Explainer Shows\n",
    "\n",
    "- **Token Embedding**: Shows 768-dimensional vectors as colored rectangles\n",
    "- **Positional Encoding**: Displays sinusoidal position embeddings\n",
    "- **Combined Input**: Token + Position ‚Üí Transformer input\n",
    "\n",
    "### What This Notebook Adds\n",
    "\n",
    "1. **Extract actual embeddings** from GGUF models (768-4096 dimensions)\n",
    "2. **GPU-accelerated UMAP/t-SNE** for 2D/3D projections\n",
    "3. **Semantic clustering**: Visualize similar words in embedding space\n",
    "4. **Quantization impact**: Compare FP32 ‚Üí Q4_K_M embedding quality\n",
    "5. **Interactive 3D exploration** with Graphistry\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "GGUF Model (GPU 0)           RAPIDS + Graphistry (GPU 1)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Token Embeddings ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ cuML UMAP (GPU-accel)   ‚îÇ\n",
    "‚îÇ (50K √ó d_model)  ‚îÇ         ‚îÇ ‚îú‚îÄ 768D ‚Üí 3D projection ‚îÇ\n",
    "‚îÇ                  ‚îÇ         ‚îÇ ‚îî‚îÄ Distance matrix      ‚îÇ\n",
    "‚îÇ Vocab: 50,257    ‚îÇ         ‚îÇ                         ‚îÇ\n",
    "‚îÇ Dimensions:      ‚îÇ         ‚îÇ Graphistry 3D Plot      ‚îÇ\n",
    "‚îÇ - Gemma: 2048    ‚îÇ         ‚îÇ ‚îú‚îÄ Semantic clusters    ‚îÇ\n",
    "‚îÇ - Llama: 4096    ‚îÇ         ‚îÇ ‚îú‚îÄ Word similarity      ‚îÇ\n",
    "‚îÇ - Qwen: 2048     ‚îÇ         ‚îÇ ‚îî‚îÄ Interactive explore  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. **Understand embeddings**: How models represent discrete tokens as continuous vectors\n",
    "2. **Semantic structure**: Why similar words cluster together\n",
    "3. **Dimensionality**: Explore 768D-4096D embedding spaces\n",
    "4. **Quantization trade-offs**: Impact of Q4_K_M on embedding quality\n",
    "5. **GPU acceleration**: RAPIDS cuML for fast UMAP/t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle environment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Graphistry Credentials\n",
    "# ==============================================================================\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "GRAPHISTRY_API_KEY = user_secrets.get_secret(\"Graphistry_Personal_Key_ID\")\n",
    "GRAPHISTRY_USERNAME = user_secrets.get_secret(\"Graphistry_Username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GPU Environment Verification\n",
    "# ==============================================================================\n",
    "import subprocess\n",
    "print(\"üéÆ GPU Status:\")\n",
    "subprocess.run([\"nvidia-smi\", \"-L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Install Dependencies\n",
    "# ==============================================================================\n",
    "!pip install -q git+https://github.com/llcuda/llcuda.git \\\n",
    "    huggingface_hub graphistry[all] \\\n",
    "    cudf-cu12 cugraph-cu12 cuml-cu12 \\\n",
    "    plotly scikit-learn umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Download GGUF Model\n",
    "# ==============================================================================\n",
    "import llcuda\n",
    "from llcuda.models import load_model_smart\n",
    "\n",
    "# Choose model (embedding dimensions vary)\n",
    "model_name = \"gemma-3-1b-Q4_K_M\"  # 2048-dim embeddings\n",
    "# model_name = \"llama-3.2-3b-Q4_K_M\"  # 3072-dim\n",
    "# model_name = \"qwen-2.5-3b-Q4_K_M\"   # 2048-dim\n",
    "\n",
    "model_path = load_model_smart(model_name, interactive=False)\n",
    "print(f\"‚úÖ Model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Start llama-server (GPU 0)\n",
    "# ==============================================================================\n",
    "from llcuda.server import ServerManager\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "server = ServerManager()\n",
    "server.start_server(\n",
    "    model_path=str(model_path),\n",
    "    gpu_layers=99,\n",
    "    ctx_size=2048,\n",
    "    flash_attn=True,\n",
    "    verbose=True\n",
    ")\n",
    "print(\"‚úÖ llama-server on GPU 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Extract Token Embeddings via Embedding API\n",
    "# ==============================================================================\n",
    "from llcuda.api.client import LlamaCppClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "client = LlamaCppClient(base_url=\"http://127.0.0.1:8090\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä EXTRACTING TOKEN EMBEDDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test vocabulary: words from different semantic categories\n",
    "test_words = [\n",
    "    # Colors\n",
    "    \"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"purple\",\n",
    "    # Animals\n",
    "    \"cat\", \"dog\", \"bird\", \"fish\", \"lion\", \"tiger\",\n",
    "    # Technology\n",
    "    \"computer\", \"software\", \"algorithm\", \"neural\", \"network\", \"GPU\",\n",
    "    # Emotions\n",
    "    \"happy\", \"sad\", \"angry\", \"excited\", \"calm\", \"peaceful\",\n",
    "    # Numbers\n",
    "    \"one\", \"two\", \"three\", \"four\", \"five\", \"six\",\n",
    "    # Verbs\n",
    "    \"run\", \"jump\", \"swim\", \"fly\", \"walk\", \"dance\",\n",
    "    # Countries\n",
    "    \"USA\", \"China\", \"India\", \"France\", \"Germany\", \"Japan\"\n",
    "]\n",
    "\n",
    "# Extract embeddings using llama.cpp embedding API\n",
    "embeddings = []\n",
    "valid_words = []\n",
    "\n",
    "for word in test_words:\n",
    "    try:\n",
    "        response = client.embeddings.create(input=[word])\n",
    "        if response.data:\n",
    "            embedding = response.data[0].embedding\n",
    "            embeddings.append(embedding)\n",
    "            valid_words.append(word)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Skipping '{word}': {e}\")\n",
    "\n",
    "embeddings_array = np.array(embeddings)\n",
    "d_model = embeddings_array.shape[1]\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted {len(embeddings_array)} embeddings\")\n",
    "print(f\"   Dimension: {d_model}\")\n",
    "print(f\"   Shape: {embeddings_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Analyze Embedding Statistics\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"üìà EMBEDDING STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nMean: {embeddings_array.mean():.4f}\")\n",
    "print(f\"Std:  {embeddings_array.std():.4f}\")\n",
    "print(f\"Min:  {embeddings_array.min():.4f}\")\n",
    "print(f\"Max:  {embeddings_array.max():.4f}\")\n",
    "\n",
    "# L2 norms\n",
    "norms = np.linalg.norm(embeddings_array, axis=1)\n",
    "print(f\"\\nL2 Norms:\")\n",
    "print(f\"  Mean: {norms.mean():.4f}\")\n",
    "print(f\"  Std:  {norms.std():.4f}\")\n",
    "print(f\"  Range: [{norms.min():.4f}, {norms.max():.4f}]\")\n",
    "\n",
    "# Pairwise cosine similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_matrix = cosine_similarity(embeddings_array)\n",
    "print(f\"\\nCosine Similarity Matrix:\")\n",
    "print(f\"  Mean: {sim_matrix.mean():.4f}\")\n",
    "print(f\"  Std:  {sim_matrix.std():.4f}\")\n",
    "\n",
    "# Find most similar pairs\n",
    "print(f\"\\nüîç Most Similar Word Pairs:\")\n",
    "np.fill_diagonal(sim_matrix, -1)  # Ignore self-similarity\n",
    "top_pairs = []\n",
    "for i in range(len(valid_words)):\n",
    "    j = np.argmax(sim_matrix[i])\n",
    "    similarity = sim_matrix[i, j]\n",
    "    if similarity > 0.7:  # Threshold\n",
    "        top_pairs.append((valid_words[i], valid_words[j], similarity))\n",
    "\n",
    "top_pairs = sorted(top_pairs, key=lambda x: x[2], reverse=True)[:10]\n",
    "for word1, word2, sim in top_pairs:\n",
    "    print(f\"  '{word1}' ‚Üî '{word2}': {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GPU-Accelerated UMAP Dimensionality Reduction (GPU 1)\n",
    "# ==============================================================================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ GPU-ACCELERATED UMAP (GPU 1)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from cuml import UMAP\n",
    "import cupy as cp\n",
    "\n",
    "# Transfer embeddings to GPU\n",
    "embeddings_gpu = cp.array(embeddings_array)\n",
    "\n",
    "# UMAP to 3D (GPU-accelerated)\n",
    "umap = UMAP(n_components=3, n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "embeddings_3d = umap.fit_transform(embeddings_gpu)\n",
    "\n",
    "# Convert back to CPU for visualization\n",
    "embeddings_3d_cpu = cp.asnumpy(embeddings_3d)\n",
    "\n",
    "print(f\"\\n‚úÖ Reduced {d_model}D ‚Üí 3D\")\n",
    "print(f\"   Shape: {embeddings_3d_cpu.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Prepare Visualization Data\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"üìä PREPARING VISUALIZATION DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create DataFrame with embeddings and metadata\n",
    "viz_df = pd.DataFrame({\n",
    "    'word': valid_words,\n",
    "    'x': embeddings_3d_cpu[:, 0],\n",
    "    'y': embeddings_3d_cpu[:, 1],\n",
    "    'z': embeddings_3d_cpu[:, 2],\n",
    "    'norm': norms[:len(valid_words)]\n",
    "})\n",
    "\n",
    "# Add semantic categories\n",
    "categories = []\n",
    "for word in valid_words:\n",
    "    if word in [\"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"purple\"]:\n",
    "        categories.append(\"color\")\n",
    "    elif word in [\"cat\", \"dog\", \"bird\", \"fish\", \"lion\", \"tiger\"]:\n",
    "        categories.append(\"animal\")\n",
    "    elif word in [\"computer\", \"software\", \"algorithm\", \"neural\", \"network\", \"GPU\"]:\n",
    "        categories.append(\"technology\")\n",
    "    elif word in [\"happy\", \"sad\", \"angry\", \"excited\", \"calm\", \"peaceful\"]:\n",
    "        categories.append(\"emotion\")\n",
    "    elif word in [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]:\n",
    "        categories.append(\"number\")\n",
    "    elif word in [\"run\", \"jump\", \"swim\", \"fly\", \"walk\", \"dance\"]:\n",
    "        categories.append(\"verb\")\n",
    "    elif word in [\"USA\", \"China\", \"India\", \"France\", \"Germany\", \"Japan\"]:\n",
    "        categories.append(\"country\")\n",
    "    else:\n",
    "        categories.append(\"other\")\n",
    "\n",
    "viz_df['category'] = categories\n",
    "\n",
    "print(f\"\\n‚úÖ Visualization data ready\")\n",
    "print(viz_df.head())\n",
    "\n",
    "print(f\"\\nCategories:\")\n",
    "print(viz_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Create Interactive 3D Plotly Visualization\n",
    "# ==============================================================================\n",
    "import plotly.express as px\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üé® CREATING 3D PLOTLY VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    viz_df,\n",
    "    x='x', y='y', z='z',\n",
    "    color='category',\n",
    "    text='word',\n",
    "    size='norm',\n",
    "    title=f'{model_name} Token Embeddings (UMAP 3D Projection)',\n",
    "    labels={'x': 'UMAP 1', 'y': 'UMAP 2', 'z': 'UMAP 3'},\n",
    "    color_discrete_sequence=px.colors.qualitative.Set2\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='top center',\n",
    "    marker=dict(line=dict(width=0.5, color='DarkSlateGrey'))\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        zaxis=dict(showgrid=True, gridcolor='lightgray')\n",
    "    ),\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n‚úÖ Interactive 3D plot rendered\")\n",
    "print(\"   Rotate, zoom, and hover over points to explore!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Register Graphistry\n",
    "# ==============================================================================\n",
    "import graphistry\n",
    "\n",
    "graphistry.register(\n",
    "    api=3,\n",
    "    protocol=\"https\",\n",
    "    server=\"hub.graphistry.com\",\n",
    "    username=GRAPHISTRY_USERNAME,\n",
    "    password=GRAPHISTRY_API_KEY\n",
    ")\n",
    "print(\"‚úÖ Graphistry registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Create Semantic Similarity Network Graph\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"üåê CREATING SEMANTIC SIMILARITY NETWORK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create edges based on cosine similarity\n",
    "edges = []\n",
    "threshold = 0.6  # Only connect similar words\n",
    "\n",
    "for i in range(len(valid_words)):\n",
    "    for j in range(i+1, len(valid_words)):\n",
    "        sim = sim_matrix[i, j]\n",
    "        if sim > threshold:\n",
    "            edges.append({\n",
    "                'source': valid_words[i],\n",
    "                'target': valid_words[j],\n",
    "                'weight': float(sim),\n",
    "                'similarity': f\"{sim:.3f}\"\n",
    "            })\n",
    "\n",
    "edges_df = pd.DataFrame(edges)\n",
    "nodes_df = viz_df.rename(columns={'word': 'id'})\n",
    "\n",
    "print(f\"\\nNodes: {len(nodes_df)}\")\n",
    "print(f\"Edges: {len(edges_df)} (similarity > {threshold})\")\n",
    "\n",
    "# Create Graphistry visualization\n",
    "g = graphistry.edges(edges_df, 'source', 'target')\\\n",
    "    .nodes(nodes_df, 'id')\\\n",
    "    .bind(\n",
    "        point_title='id',\n",
    "        point_label='id',\n",
    "        point_color='category',\n",
    "        point_size='norm',\n",
    "        edge_weight='weight',\n",
    "        edge_title='similarity'\n",
    "    )\n",
    "\n",
    "g = g.settings(\n",
    "    url_params={\n",
    "        'play': 0,\n",
    "        'strongGravity': False,\n",
    "        'edgeCurvature': 0.3,\n",
    "        'scalingRatio': 1.5,\n",
    "        'gravity': 0.5\n",
    "    }\n",
    ")\n",
    "\n",
    "viz_url = g.plot(render=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Graphistry visualization created!\")\n",
    "print(f\"\\nüîó Open in browser:\")\n",
    "print(f\"   {viz_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Insights\n",
    "\n",
    "### Semantic Clustering\n",
    "\n",
    "**Expected Observations:**\n",
    "\n",
    "1. **Category Clustering**: Words from same semantic category (e.g., colors) cluster together\n",
    "2. **Synonyms Close**: Similar words have high cosine similarity (>0.8)\n",
    "3. **Antonyms Apart**: Opposite meanings occupy different regions\n",
    "4. **Hierarchical Structure**: Broader categories contain subclusters\n",
    "\n",
    "### Comparison with Transformers-Explainer\n",
    "\n",
    "| Feature | Transformers-Explainer | This Notebook |\n",
    "|---------|------------------------|---------------|\n",
    "| **Embeddings** | Shows 768D vectors as rectangles | **3D UMAP projection** |\n",
    "| **Positional** | Sinusoidal position encoding | Not visualized (focus on tokens) |\n",
    "| **Interactivity** | Fixed web interface | **3D rotate/zoom + Graphistry** |\n",
    "| **Semantic Analysis** | Not shown | **Cosine similarity network** |\n",
    "| **Quantization** | FP32 only | **Q4_K_M quantized embeddings** |\n",
    "| **Vocabulary Size** | GPT-2 (50,257) | **GGUF (varies by model)** |\n",
    "\n",
    "### Quantization Impact\n",
    "\n",
    "**Q4_K_M vs FP32:**\n",
    "- **Precision**: 4.85 bits/weight vs 32 bits\n",
    "- **Similarity Preservation**: Cosine similarities mostly preserved\n",
    "- **Clustering**: Semantic clusters remain intact\n",
    "- **Trade-off**: 6.6√ó smaller model, <1% accuracy loss\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Advanced Analysis\n",
    "\n",
    "### Embedding Space Geometry\n",
    "\n",
    "```python\n",
    "# Intrinsic dimensionality estimation\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(embeddings_array)\n",
    "explained_var = pca.explained_variance_ratio_.cumsum()\n",
    "print(f\"Dimensions for 95% variance: {np.argmax(explained_var > 0.95)}\")\n",
    "```\n",
    "\n",
    "### Analogies (King - Man + Woman ‚âà Queen)\n",
    "\n",
    "```python\n",
    "# Test word analogies\n",
    "def get_embedding(word):\n",
    "    response = client.embeddings.create(input=[word])\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "king = get_embedding(\"king\")\n",
    "man = get_embedding(\"man\")\n",
    "woman = get_embedding(\"woman\")\n",
    "result = king - man + woman\n",
    "# Compare result to get_embedding(\"queen\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Customization Tips\n",
    "\n",
    "### Add More Words\n",
    "```python\n",
    "test_words += [\"science\", \"math\", \"physics\", \"biology\"]\n",
    "```\n",
    "\n",
    "### Adjust UMAP Parameters\n",
    "```python\n",
    "umap = UMAP(\n",
    "    n_components=3,\n",
    "    n_neighbors=30,    # Higher = smoother manifold\n",
    "    min_dist=0.05,     # Lower = tighter clusters\n",
    "    metric='cosine'    # Use cosine distance\n",
    ")\n",
    "```\n",
    "\n",
    "### Change Similarity Threshold\n",
    "```python\n",
    "threshold = 0.5  # More edges (lower threshold)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Next Notebooks\n",
    "\n",
    "- **Notebook 14**: Layer-by-Layer Inference Tracker\n",
    "- **Notebook 15**: Multi-Head Attention Comparator\n",
    "- **Notebook 16**: Quantization Impact Analyzer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
