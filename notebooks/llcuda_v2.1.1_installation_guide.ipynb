{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be4b78e",
   "metadata": {},
   "source": [
    "# llcuda v2.1.1 Installation & Setup Guide\n",
    "\n",
    "This notebook provides a reliable way to install and validate llcuda v2.1.1, handling common issues and providing proper error diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b6b5b",
   "metadata": {},
   "source": [
    "## Section 1: Verify Package Availability\n",
    "\n",
    "Check PyPI and GitHub for available versions of llcuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "print(\"üîç Checking PyPI for llcuda versions...\\n\")\n",
    "\n",
    "# Check PyPI for available versions\n",
    "result = subprocess.run(\n",
    "    [\"pip\", \"index\", \"versions\", \"llcuda\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(\"PyPI Status:\")\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"(Using pip search fallback...)\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ GitHub Release Information:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Repository: https://github.com/llcuda/llcuda/\")\n",
    "print(\"Latest Release: v2.1.1\")\n",
    "print(\"Release URL: https://github.com/llcuda/llcuda/releases/tag/v2.1.1\")\n",
    "print(\"\\nNote: v2.1.1 is available on GitHub but may not yet be on PyPI.\")\n",
    "print(\"We'll install directly from the GitHub repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c8104",
   "metadata": {},
   "source": [
    "## Section 2: Install from Source Repository\n",
    "\n",
    "Install llcuda directly from GitHub using pip's git support. This is the recommended approach for v2.1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea413d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üì• Installing llcuda v2.1.1 from GitHub Repository...\\n\")\n",
    "print(\"This will download from: https://github.com/llcuda/llcuda.git@v2.1.1\\n\")\n",
    "\n",
    "# Install from GitHub\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
    "     \"git+https://github.com/llcuda/llcuda.git@v2.1.1\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Installation successful!\")\n",
    "else:\n",
    "    print(\"‚ùå Installation encountered issues:\")\n",
    "    print(result.stderr)\n",
    "    if \"Could not find\" in result.stderr or \"No matching\" in result.stderr:\n",
    "        print(\"\\nüí° Hint: The tag may not be available yet. Trying latest main branch...\")\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "             \"git+https://github.com/llcuda/llcuda.git\"],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Installed from main branch successfully!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Installation failed. See error above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715c36f",
   "metadata": {},
   "source": [
    "## Section 3: Handle Installation Errors\n",
    "\n",
    "Implement error handling to catch and diagnose installation failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db72100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def diagnose_installation():\n",
    "    \"\"\"Comprehensive diagnosis of llcuda installation status.\"\"\"\n",
    "    \n",
    "    print(\"üîß Running Installation Diagnostics...\\n\")\n",
    "    \n",
    "    # Check 1: Git availability\n",
    "    print(\"1. Checking Git availability...\")\n",
    "    try:\n",
    "        result = subprocess.run([\"git\", \"--version\"], capture_output=True, text=True, timeout=5)\n",
    "        print(f\"   ‚úÖ {result.stdout.strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Git not available: {e}\")\n",
    "        print(\"   üí° Install git: sudo apt-get install git\")\n",
    "    \n",
    "    # Check 2: Network connectivity\n",
    "    print(\"\\n2. Checking network connectivity to GitHub...\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", \"-m\", \"pip\", \"index\", \"versions\", \"llcuda\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        print(\"   ‚úÖ Network connection OK\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Network issue: {e}\")\n",
    "        print(\"   üí° Check your internet connection or firewall\")\n",
    "    \n",
    "    # Check 3: pip version\n",
    "    print(\"\\n3. Checking pip version...\")\n",
    "    result = subprocess.run([sys.executable, \"-m\", \"pip\", \"--version\"], \n",
    "                          capture_output=True, text=True)\n",
    "    print(f\"   ‚úÖ {result.stdout.strip()}\")\n",
    "    \n",
    "    # Check 4: Python version\n",
    "    print(\"\\n4. Checking Python version...\")\n",
    "    print(f\"   ‚úÖ Python {sys.version.split()[0]} (Required: 3.11+)\")\n",
    "    if sys.version_info < (3, 11):\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: llcuda v2.1.1 requires Python 3.11 or higher\")\n",
    "    \n",
    "    # Check 5: NVIDIA GPU\n",
    "    print(\"\\n5. Checking for NVIDIA GPU...\")\n",
    "    try:\n",
    "        result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,compute_cap\", \"--format=csv,noheader\"],\n",
    "                              capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            gpus = result.stdout.strip().split('\\n')\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                print(f\"   ‚úÖ GPU {i+1}: {gpu}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  No NVIDIA GPU detected (nvidia-smi not found)\")\n",
    "            print(\"   üí° This is OK - llcuda will use CPU fallback\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not detect GPU: {e}\")\n",
    "        print(\"   üí° This is OK - llcuda will use CPU fallback\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Diagnostics Complete\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Run diagnostics\n",
    "diagnose_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca6154",
   "metadata": {},
   "source": [
    "## Section 4: Validate Installation Success\n",
    "\n",
    "Verify that llcuda was installed correctly and check version compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c240efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Validating llcuda Installation...\\n\")\n",
    "\n",
    "try:\n",
    "    import llcuda\n",
    "    print(f\"‚úÖ llcuda imported successfully\")\n",
    "    print(f\"   Package location: {llcuda.__file__}\")\n",
    "    print(f\"   Version: {llcuda.__version__}\")\n",
    "    \n",
    "    # Verify version\n",
    "    version = llcuda.__version__\n",
    "    if version.startswith(\"2.1\"):\n",
    "        print(f\"\\n‚úÖ Version {version} is compatible with v2.1.x series\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Version {version} - Expected 2.1.x series\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import llcuda: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting steps:\")\n",
    "    print(\"   1. Check installation completed without errors above\")\n",
    "    print(\"   2. Restart the kernel (Kernel ‚Üí Restart)\")\n",
    "    print(\"   3. Try running the installation cell again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea99e42",
   "metadata": {},
   "source": [
    "## Section 5: Configure CUDA Binary Caching\n",
    "\n",
    "Set up proper caching directories for CUDA binaries and verify the auto-download mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì¶ CUDA Binary Caching Configuration\\n\")\n",
    "\n",
    "# Check cache directories\n",
    "cache_locations = [\n",
    "    Path.home() / \".cache\" / \"llcuda\",\n",
    "    Path.home() / \".llcuda\",\n",
    "]\n",
    "\n",
    "print(\"Expected cache locations:\")\n",
    "for cache_dir in cache_locations:\n",
    "    status = \"‚úÖ exists\" if cache_dir.exists() else \"‚è≥ will be created on first import\"\n",
    "    size = \"\"\n",
    "    if cache_dir.exists():\n",
    "        total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())\n",
    "        size = f\" ({total_size / (1024**2):.1f} MB)\"\n",
    "    print(f\"   {cache_dir}{size} - {status}\")\n",
    "\n",
    "print(\"\\nüì• First Import Behavior:\")\n",
    "print(\"   1. llcuda will be imported\")\n",
    "print(\"   2. Auto-detection of GPU (Tesla T4, RTX, A100, H100, etc.)\")\n",
    "print(\"   3. Download v2.1.1 CUDA binaries (~267 MB) to cache\")\n",
    "print(\"   4. Extract and configure paths\")\n",
    "print(\"   5. Subsequent imports use cached binaries\")\n",
    "\n",
    "print(\"\\nüöÄ Starting first import (this may take a minute)...\\n\")\n",
    "\n",
    "try:\n",
    "    import llcuda\n",
    "    print(\"‚úÖ First import successful!\")\n",
    "    print(\"   CUDA binaries are now cached and ready to use\")\n",
    "    print(\"\\n‚ú® Features in v2.1.1:\")\n",
    "    print(\"   ‚Ä¢ Fixed llama-server fallback mechanism\")\n",
    "    print(\"   ‚Ä¢ Full compatibility with Tesla T4 and newer GPUs\")\n",
    "    print(\"   ‚Ä¢ Automatic model downloading from Hugging Face\")\n",
    "    print(\"   ‚Ä¢ High-performance inference with FlashAttention\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Import encountered an issue: {e}\")\n",
    "    print(\"\\nCommon solutions:\")\n",
    "    print(\"   ‚Ä¢ GPU compatibility: Requires SM 7.5+ (Tesla T4, RTX 20xx+, A100+)\")\n",
    "    print(\"   ‚Ä¢ Storage space: Ensure 1GB free space for binaries + models\")\n",
    "    print(\"   ‚Ä¢ Network: Check internet connection for binary download\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
