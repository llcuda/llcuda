{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ac8a0f",
   "metadata": {},
   "source": [
    "## Step 1: Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”§ ENVIRONMENT CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š PyTorch Version: {torch.__version__}\")\n",
    "print(f\"ğŸ“Š CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"ğŸ“Š GPU Count: {torch.cuda.device_count()}\")\n",
    "print(f\"ğŸ“Š NCCL Available: {torch.cuda.nccl.is_available(torch.cuda.device_count())}\")\n",
    "print(f\"ğŸ“Š cuDNN Version: {torch.backends.cudnn.version()}\")\n",
    "\n",
    "# List GPUs\n",
    "print(\"\\nğŸ“Š GPU Details:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    props = torch.cuda.get_device_properties(i)\n",
    "    print(f\"   GPU {i}: {props.name}\")\n",
    "    print(f\"          Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"          Compute: {props.major}.{props.minor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92df376",
   "metadata": {},
   "source": [
    "## Step 2: NCCL Basics - All-Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”— NCCL ALL-REDUCE EXAMPLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def setup_nccl(rank, world_size):\n",
    "    \"\"\"Initialize NCCL process group.\"\"\"\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    \n",
    "    dist.init_process_group(\n",
    "        backend='nccl',\n",
    "        rank=rank,\n",
    "        world_size=world_size\n",
    "    )\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Cleanup NCCL.\"\"\"\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def all_reduce_demo(rank, world_size):\n",
    "    \"\"\"Demonstrate NCCL all-reduce.\"\"\"\n",
    "    setup_nccl(rank, world_size)\n",
    "    \n",
    "    # Create tensor on each GPU\n",
    "    torch.cuda.set_device(rank)\n",
    "    tensor = torch.tensor([rank + 1.0], device=f'cuda:{rank}')\n",
    "    \n",
    "    print(f\"[GPU {rank}] Before all-reduce: {tensor.item()}\")\n",
    "    \n",
    "    # All-reduce (sum across GPUs)\n",
    "    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n",
    "    \n",
    "    print(f\"[GPU {rank}] After all-reduce: {tensor.item()}\")\n",
    "    \n",
    "    cleanup()\n",
    "\n",
    "# Note: In Kaggle notebook, run distributed code via subprocess\n",
    "# This is a conceptual example\n",
    "print(\"\"\"\n",
    "ğŸ“‹ NCCL All-Reduce Pattern:\n",
    "\n",
    "   Before:    GPU 0: [1.0]     GPU 1: [2.0]\n",
    "                 \\               /\n",
    "                  \\    NCCL    /\n",
    "                   \\  All-Reduce /\n",
    "                    \\         /\n",
    "                     v       v\n",
    "   After:     GPU 0: [3.0]     GPU 1: [3.0]\n",
    "\n",
    "   Result: Sum of all tensors replicated on each GPU\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218ff1b",
   "metadata": {},
   "source": [
    "## Step 3: Simple Multi-GPU Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b58469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ”¢ MULTI-GPU TENSOR OPERATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Without NCCL - Direct GPU tensor operations\n",
    "if torch.cuda.device_count() >= 2:\n",
    "    # Create tensors on different GPUs\n",
    "    a = torch.randn(1000, 1000, device='cuda:0')\n",
    "    b = torch.randn(1000, 1000, device='cuda:1')\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Tensor A on GPU 0: {a.shape}\")\n",
    "    print(f\"ğŸ“Š Tensor B on GPU 1: {b.shape}\")\n",
    "    \n",
    "    # Move tensor from GPU 1 to GPU 0\n",
    "    b_on_gpu0 = b.to('cuda:0')\n",
    "    print(f\"\\nğŸ“Š B moved to GPU 0\")\n",
    "    \n",
    "    # Now we can do operations\n",
    "    c = a @ b_on_gpu0\n",
    "    print(f\"ğŸ“Š Result C = A @ B: {c.shape}\")\n",
    "    \n",
    "    # Memory status\n",
    "    for i in range(2):\n",
    "        mem = torch.cuda.memory_allocated(i) / 1024**2\n",
    "        print(f\"ğŸ“Š GPU {i} memory used: {mem:.1f} MB\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del a, b, b_on_gpu0, c\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nâœ… Tensors cleaned up\")\n",
    "else:\n",
    "    print(\"âš ï¸ Need 2 GPUs for this demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4d0f6",
   "metadata": {},
   "source": [
    "## Step 4: Data Parallel Training Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š DATA PARALLEL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=2048, output_dim=512):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Create model and wrap with DataParallel\n",
    "model = SimpleModel().cuda()\n",
    "\n",
    "if torch.cuda.device_count() >= 2:\n",
    "    # Use both GPUs\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    print(\"\\nâœ… Model wrapped with DataParallel (GPU 0, 1)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Single GPU mode\")\n",
    "\n",
    "print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")\n",
    "\n",
    "# Test forward pass\n",
    "batch = torch.randn(64, 1024).cuda()\n",
    "output = model(batch)\n",
    "print(f\"ğŸ“Š Input: {batch.shape} â†’ Output: {output.shape}\")\n",
    "\n",
    "# Cleanup\n",
    "del model, batch, output\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b223cec",
   "metadata": {},
   "source": [
    "## Step 5: DistributedDataParallel Script Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ”§ DDP TRAINING SCRIPT PATTERN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ddp_script = '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"DDP Training Script for Kaggle Dual T4\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def train(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    \n",
    "    # Model\n",
    "    model = nn.Linear(1024, 512).cuda(rank)\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    \n",
    "    # Fake dataset\n",
    "    dataset = TensorDataset(\n",
    "        torch.randn(1000, 1024),\n",
    "        torch.randn(1000, 512)\n",
    "    )\n",
    "    \n",
    "    # Distributed sampler\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    loader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "    \n",
    "    # Training loop\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        sampler.set_epoch(epoch)  # Important!\n",
    "        for x, y in loader:\n",
    "            x, y = x.cuda(rank), y.cuda(rank)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()  # NCCL syncs gradients here\n",
    "            optimizer.step()\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\"Epoch {epoch+1} complete\")\n",
    "    \n",
    "    cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    world_size = torch.cuda.device_count()\n",
    "    torch.multiprocessing.spawn(train, args=(world_size,), nprocs=world_size)\n",
    "'''\n",
    "\n",
    "# Save script\n",
    "with open('/kaggle/working/ddp_train.py', 'w') as f:\n",
    "    f.write(ddp_script)\n",
    "\n",
    "print(\"\\nğŸ“ DDP training script saved to /kaggle/working/ddp_train.py\")\n",
    "print(\"\\nğŸ“‹ Key DDP Concepts:\")\n",
    "print(\"   â€¢ DistributedSampler splits data across GPUs\")\n",
    "print(\"   â€¢ DDP automatically syncs gradients via NCCL\")\n",
    "print(\"   â€¢ sampler.set_epoch() for proper shuffling\")\n",
    "print(\"   â€¢ Each GPU processes batch_size samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7821e2",
   "metadata": {},
   "source": [
    "## Step 6: Run DDP Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸƒ RUNNING DDP TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "!python /kaggle/working/ddp_train.py\n",
    "\n",
    "print(\"\\nâœ… DDP training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4f73e",
   "metadata": {},
   "source": [
    "## Step 7: NCCL with llcuda Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af795cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ”Œ COMBINING DDP TRAINING + LLCUDA INFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ“‹ Architecture Pattern:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TRAINING + INFERENCE PIPELINE                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                     â”‚\n",
    "â”‚   PHASE 1: Fine-tuning with DDP                                    â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚\n",
    "â”‚   â”‚   GPU 0 (T4)    â”‚â—„â”€â”€â”€â”€â–ºâ”‚   GPU 1 (T4)    â”‚   NCCL             â”‚\n",
    "â”‚   â”‚   Model Shard   â”‚      â”‚   Model Shard   â”‚   All-Reduce       â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚\n",
    "â”‚            â”‚                        â”‚                               â”‚\n",
    "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚\n",
    "â”‚                     â–¼                                               â”‚\n",
    "â”‚             [Fine-tuned Model]                                      â”‚\n",
    "â”‚                     â”‚                                               â”‚\n",
    "â”‚                     â–¼                                               â”‚\n",
    "â”‚   PHASE 2: Export to GGUF                                          â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚   â”‚   Unsloth merge + GGUF quantization   â”‚                        â”‚\n",
    "â”‚   â”‚   â†’ model.Q4_K_M.gguf                 â”‚                        â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\n",
    "â”‚                       â–¼                                             â”‚\n",
    "â”‚   PHASE 3: Inference with llcuda                                   â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚\n",
    "â”‚   â”‚   GPU 0 (T4)    â”‚â—„â”€â”€â”€â”€â–ºâ”‚   GPU 1 (T4)    â”‚   tensor-split     â”‚\n",
    "â”‚   â”‚   llama-server  â”‚      â”‚   llama-server  â”‚   (native CUDA)    â”‚\n",
    "â”‚   â”‚   Layers 0-15   â”‚      â”‚   Layers 16-31  â”‚                     â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚\n",
    "â”‚                                                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "ğŸ“ Notes:\n",
    "â€¢ Training: Uses NCCL for gradient synchronization\n",
    "â€¢ Inference: Uses native CUDA tensor-split (NOT NCCL)\n",
    "â€¢ Memory: Can run both phases with proper cleanup\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06534163",
   "metadata": {},
   "source": [
    "## Step 8: NCCL Operations Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ“š NCCL OPERATIONS REFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ”¹ Collective Operations:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Operation        â”‚ Description                                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ all_reduce       â”‚ Reduce + Broadcast (sum/avg across all GPUs)    â”‚\n",
    "â”‚ all_gather       â”‚ Gather tensors from all GPUs to all GPUs        â”‚\n",
    "â”‚ reduce           â”‚ Reduce to single GPU                            â”‚\n",
    "â”‚ broadcast        â”‚ Send from one GPU to all GPUs                   â”‚\n",
    "â”‚ reduce_scatter   â”‚ Reduce + Scatter result                         â”‚\n",
    "â”‚ all_to_all       â”‚ Full exchange between all GPUs                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "ğŸ”¹ Reduce Operations:\n",
    "\n",
    "   dist.ReduceOp.SUM      - Sum values\n",
    "   dist.ReduceOp.PRODUCT  - Multiply values\n",
    "   dist.ReduceOp.MIN      - Minimum value\n",
    "   dist.ReduceOp.MAX      - Maximum value\n",
    "   dist.ReduceOp.AVG      - Average values\n",
    "\n",
    "ğŸ”¹ Common Patterns:\n",
    "\n",
    "   # Gradient sync (DDP does this automatically)\n",
    "   dist.all_reduce(gradient, op=dist.ReduceOp.SUM)\n",
    "   gradient /= world_size\n",
    "   \n",
    "   # Gather outputs from all GPUs\n",
    "   gathered = [torch.zeros_like(tensor) for _ in range(world_size)]\n",
    "   dist.all_gather(gathered, tensor)\n",
    "   \n",
    "   # Broadcast from rank 0\n",
    "   dist.broadcast(tensor, src=0)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3bf4a",
   "metadata": {},
   "source": [
    "## Step 9: Memory Management for DDP + Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ’¾ MEMORY MANAGEMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def cleanup_gpu_memory():\n",
    "    \"\"\"Clean up GPU memory after training before inference.\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    print(\"\\nğŸ“Š GPU Memory After Cleanup:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**2\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**2\n",
    "        print(f\"   GPU {i}: {allocated:.1f} MB allocated, {reserved:.1f} MB reserved\")\n",
    "\n",
    "cleanup_gpu_memory()\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ“‹ Memory Strategy:\n",
    "\n",
    "1. After DDP Training:\n",
    "   â€¢ Call dist.destroy_process_group()\n",
    "   â€¢ Delete model, optimizer, data loaders\n",
    "   â€¢ Call cleanup_gpu_memory()\n",
    "\n",
    "2. Before llcuda Inference:\n",
    "   â€¢ Ensure training cleanup is complete\n",
    "   â€¢ Start llama-server with appropriate model\n",
    "   â€¢ Use --tensor-split for multi-GPU\n",
    "\n",
    "3. T4 Memory Budget:\n",
    "   â€¢ Total: 15GB per GPU (30GB total)\n",
    "   â€¢ DDP Training: ~10-12GB per GPU\n",
    "   â€¢ Inference: Q4_K_M 7B fits on single T4\n",
    "   â€¢ Inference: 70B IQ3_XS needs both T4s\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95379aa",
   "metadata": {},
   "source": [
    "## Step 10: Full Pipeline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16753d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ”„ FULL PIPELINE: TRAIN â†’ EXPORT â†’ INFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "full_pipeline = '''\n",
    "# Full Pipeline Script\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PHASE 1: DDP Training with NCCL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Run DDP training script\n",
    "!torchrun --nproc_per_node=2 train_ddp.py \\\n",
    "    --model_name \"unsloth/Qwen2.5-1.5B\" \\\n",
    "    --output_dir \"./fine_tuned_model\" \\\n",
    "    --epochs 3\n",
    "\n",
    "# Cleanup GPU memory after training\n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PHASE 2: Merge & Export to GGUF\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load and merge LoRA\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\"./fine_tuned_model\")\n",
    "model.save_pretrained_merged(\"./merged_model\", tokenizer)\n",
    "\n",
    "# Export to GGUF\n",
    "model.save_pretrained_gguf(\n",
    "    \"./gguf_model\",\n",
    "    tokenizer,\n",
    "    quantization_method=\"q4_k_m\"\n",
    ")\n",
    "\n",
    "del model, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PHASE 3: Inference with llcuda\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from llcuda.server import ServerManager, ServerConfig\n",
    "\n",
    "config = ServerConfig(\n",
    "    model_path=\"./gguf_model/model-Q4_K_M.gguf\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8080,\n",
    "    n_gpu_layers=99,\n",
    "    tensor_split=\"0.5,0.5\",  # Dual T4\n",
    "    flash_attn=True,\n",
    ")\n",
    "\n",
    "server = ServerManager()\n",
    "server.start_with_config(config)\n",
    "server.wait_until_ready()\n",
    "\n",
    "# Now use OpenAI API at http://127.0.0.1:8080\n",
    "'''\n",
    "\n",
    "print(full_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c510817",
   "metadata": {},
   "source": [
    "## Step 11: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§¹ Final Cleanup\")\n",
    "\n",
    "# Clean up test script\n",
    "import os\n",
    "if os.path.exists('/kaggle/working/ddp_train.py'):\n",
    "    os.remove('/kaggle/working/ddp_train.py')\n",
    "    print(\"âœ… Removed test script\")\n",
    "\n",
    "# Clear GPU memory\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"âœ… GPU memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598fa65",
   "metadata": {},
   "source": [
    "## ğŸ“š Summary\n",
    "\n",
    "### NCCL vs llama.cpp Multi-GPU:\n",
    "\n",
    "| Feature | NCCL | llama.cpp |\n",
    "|---------|------|-----------|\n",
    "| Purpose | Training, gradient sync | Inference |\n",
    "| Protocol | All-reduce, broadcast | Tensor-split |\n",
    "| Integration | PyTorch DDP | Native CUDA |\n",
    "| Use Case | Fine-tuning | Serving |\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **NCCL** is for PyTorch distributed training\n",
    "2. **llama.cpp** uses native CUDA for multi-GPU inference\n",
    "3. Both can run on Kaggle's dual T4 GPUs\n",
    "4. Clean GPU memory between training and inference\n",
    "\n",
    "### Pipeline Pattern:\n",
    "```\n",
    "DDP Training (NCCL) â†’ GGUF Export â†’ llcuda Inference (tensor-split)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** [09-large-models-kaggle](09-large-models-kaggle-llcuda-v2.2.0.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
